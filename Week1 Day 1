
{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-SxOTr",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GroqModel-QUF8F",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-SxOTr{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-SxOTrœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-GroqModel-QUF8F{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-QUF8Fœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-SxOTr",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-SxOTrœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GroqModel-QUF8F",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-QUF8Fœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GroqModel",
            "id": "GroqModel-QUF8F",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "userStory",
            "id": "Prompt Template-oCl1e",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__GroqModel-QUF8F{œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-QUF8Fœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-oCl1e{œfieldNameœ:œuserStoryœ,œidœ:œPrompt Template-oCl1eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "GroqModel-QUF8F",
        "sourceHandle": "{œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-QUF8Fœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-oCl1e",
        "targetHandle": "{œfieldNameœ:œuserStoryœ,œidœ:œPrompt Template-oCl1eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-oCl1e",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GroqModel-rxKTk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-oCl1e{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-oCl1eœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-GroqModel-rxKTk{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-rxKTkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-oCl1e",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-oCl1eœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GroqModel-rxKTk",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-rxKTkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GroqModel",
            "id": "GroqModel-rxKTk",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input",
            "id": "SaveToFile-YfDpR",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__GroqModel-rxKTk{œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-rxKTkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-SaveToFile-YfDpR{œfieldNameœ:œinputœ,œidœ:œSaveToFile-YfDpRœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "GroqModel-rxKTk",
        "sourceHandle": "{œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-rxKTkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SaveToFile-YfDpR",
        "targetHandle": "{œfieldNameœ:œinputœ,œidœ:œSaveToFile-YfDpRœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "APIRequest",
            "id": "APIRequest-WTvte",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-SxOTr",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__APIRequest-WTvte{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-WTvteœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParserComponent-SxOTr{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-SxOTrœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "APIRequest-WTvte",
        "sourceHandle": "{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-WTvteœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-SxOTr",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-SxOTrœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ParserComponent-SxOTr",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "last_updated": "2026-01-31T09:14:38.123Z",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "3cda25c3f7b5",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.processing.parser.ParserComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "loop_types": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "d1b9d198-5844-45be-86b3-50756d36bee5"
              },
              "_frontend_node_folder_id": {
                "value": "00963bd6-b531-4d5e-bcbf-de1112750e10"
              },
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.custom.custom_component.component import Component\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            # Use format_map with a dict that returns default_value for missing keys\n            class DefaultDict(dict):\n                def __missing__(self, key):\n                    return data.default_value or \"\"\n\n            formatted_text = self.pattern.format_map(DefaultDict(data.data))\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "is_refresh": false,
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "tab",
                "value": "Stringify"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "Text: {text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-SxOTr",
        "measured": {
          "height": 246,
          "width": 320
        },
        "position": {
          "x": 445,
          "y": 158
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GroqModel-QUF8F",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Groq.",
            "display_name": "Groq",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "api_key",
              "base_url",
              "max_tokens",
              "temperature",
              "n",
              "model_name",
              "tool_model_enabled"
            ],
            "frozen": false,
            "icon": "Groq",
            "last_updated": "2026-01-31T12:59:18.363Z",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "2aee7de6ee88",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  },
                  {
                    "name": "langchain_groq",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 3
              },
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ],
              "module": "lfx.components.groq.groq.GroqModel"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "loop_types": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "d1b9d198-5844-45be-86b3-50756d36bee5"
              },
              "_frontend_node_folder_id": {
                "value": "00963bd6-b531-4d5e-bcbf-de1112750e10"
              },
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Groq API Key",
                "dynamic": false,
                "info": "API key for the Groq API.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "base_url": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Groq API Base",
                "dynamic": false,
                "info": "Base URL path for API requests, leave blank if not using a proxy or service emulator.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "base_url",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "https://api.groq.com"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pydantic.v1 import SecretStr\n\nfrom lfx.base.models.groq_constants import GROQ_MODELS\nfrom lfx.base.models.groq_model_discovery import get_groq_models\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput, SliderInput\nfrom lfx.log.logger import logger\n\n\nclass GroqModel(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n    name = \"GroqModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        SecretStrInput(\n            name=\"api_key\", display_name=\"Groq API Key\", info=\"API key for the Groq API.\", real_time_refresh=True\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Groq API Base\",\n            info=\"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n            advanced=True,\n            value=\"https://api.groq.com\",\n            real_time_refresh=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use. Add your Groq API key to access additional available models.\",\n            options=GROQ_MODELS,\n            value=GROQ_MODELS[0],\n            refresh_button=True,\n            combobox=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Enable Tool Models\",\n            info=(\n                \"Select if you want to use models that can work with tools. If yes, only those models will be shown.\"\n            ),\n            advanced=False,\n            value=False,\n            real_time_refresh=True,\n        ),\n    ]\n\n    def get_models(self, *, tool_model_enabled: bool | None = None) -> list[str]:\n        \"\"\"Get available Groq models using the dynamic discovery system.\n\n        This method uses the groq_model_discovery module which:\n        - Fetches models directly from Groq API\n        - Automatically tests tool calling support\n        - Caches results for 24 hours\n        - Falls back to hardcoded list if API fails\n\n        Args:\n            tool_model_enabled: If True, only return models that support tool calling\n\n        Returns:\n            List of available model IDs\n        \"\"\"\n        try:\n            # Get models with metadata from dynamic discovery system\n            api_key = self.api_key if hasattr(self, \"api_key\") and self.api_key else None\n            models_metadata = get_groq_models(api_key=api_key)\n\n            # Filter out non-LLM models (audio, TTS, guards)\n            model_ids = [\n                model_id for model_id, metadata in models_metadata.items() if not metadata.get(\"not_supported\", False)\n            ]\n\n            # Filter by tool calling support if requested\n            if tool_model_enabled:\n                model_ids = [model_id for model_id in model_ids if models_metadata[model_id].get(\"tool_calling\", False)]\n                logger.info(f\"Loaded {len(model_ids)} Groq models with tool calling support\")\n            else:\n                logger.info(f\"Loaded {len(model_ids)} Groq models\")\n        except (ValueError, KeyError, TypeError, ImportError) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            # Fallback to hardcoded list from groq_constants.py\n            return GROQ_MODELS\n        else:\n            return model_ids\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) != 0:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ValueError, KeyError, TypeError, ImportError) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GROQ_MODELS\n                    build_config.setdefault(\"model_name\", {})\n                    build_config[\"model_name\"][\"options\"] = ids\n                    build_config[\"model_name\"].setdefault(\"value\", ids[0])\n            except (ValueError, KeyError, TypeError, AttributeError) as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_groq import ChatGroq\n        except ImportError as e:\n            msg = \"langchain-groq is not installed. Please install it with `pip install langchain-groq`.\"\n            raise ImportError(msg) from e\n\n        return ChatGroq(\n            model=self.model_name,\n            max_tokens=self.max_tokens or None,\n            temperature=self.temperature,\n            base_url=self.base_url,\n            n=self.n or 1,\n            api_key=SecretStr(self.api_key).get_secret_value(),\n            streaming=self.stream,\n        )\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Output Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "external_options": {},
                "info": "The name of the model to use. Add your Groq API key to access additional available models.",
                "name": "model_name",
                "options": [
                  "llama-3.1-8b-instant",
                  "llama-3.3-70b-versatile"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "llama-3.3-70b-versatile"
              },
              "n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "N",
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Run inference with this temperature. Must by in the closed interval [0.0, 1.0].",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "override_skip": false,
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "track_in_telemetry": false,
                "type": "slider",
                "value": 0.1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Enable Tool Models",
                "dynamic": false,
                "info": "Select if you want to use models that can work with tools. If yes, only those models will be shown.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "GroqModel"
        },
        "dragging": false,
        "id": "GroqModel-QUF8F",
        "measured": {
          "height": 492,
          "width": 320
        },
        "position": {
          "x": 862.2399999999997,
          "y": 124.84
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-oCl1e",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "userStory"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "7382d03ce412",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.models_and_agents.prompt.PromptComponent"
            },
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.prompts.api_utils import process_prompt_template\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DefaultPromptField\nfrom lfx.io import MessageTextInput, Output, PromptInput\nfrom lfx.schema.message import Message\nfrom lfx.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "prompt",
                "value": "For this given Input as user story : {userStory}, follow these;\n\nInstructions\n\nYou are an expert AI assistant specialized in Business Analysis for Healthcare.\nYour task is to analyze and review the uploaded user story document based on multiple quality dimensions and provide:\n\nIndividual parameter scores (each out of 20)\nOverall quality score (out of 100)\n\nSpecific improvement recommendations for each weak parameter\nEvaluate the user story against the following five parameters:\nClarity: Is the story easy to understand and unambiguous?\nCompleteness: Are acceptance criteria and preconditions well-defined?\nBusiness Value Alignment: Does it reflect tangible healthcare value (e.g., patient safety, compliance, operational efficiency)?\nTestability: Can QA engineers easily derive test cases from it?\nTechnical Feasibility: Is it practically implementable within typical healthcare system constraints?\n\nFinally, provide an overall rating and improvement summary.\n\nContext\n\nThe input user story belongs to the Healthcare domain — specifically dealing with hospital systems, patient records, clinical workflows, and compliance (like HIPAA or PoPIA).\nAssume that this story will be used by a cross-functional team (BA, QA, Developer) in a regulated healthcare project.\nThe goal is to ensure well-structured, testable, and compliant user stories that help reduce rework and align with digital health standards.\nGive the output as html that is too attractive with colors and logos or clipart as applicable\n\nExample\n\nExample Input (User Story Summary):\n\nAs a doctor, I want to review and approve patient prescriptions digitally before they reach the pharmacy, ensuring safety and compliance.\n\nExample Output:\n\nParameter\tDescription\tScore (out of 20)\nClarity\tThe story is straightforward but lacks detailed acceptance criteria.\t16\nCompleteness\tPreconditions not clearly mentioned.\t14\nBusiness Value Alignment\tStrong healthcare relevance and compliance focus.\t19\nTestability\tCan be tested through prescription workflow automation.\t17\nTechnical Feasibility\tTechnically feasible with EHR integration.\t18\n\nOverall Score: 84 / 100\n\nImprovement Areas:\n\nAdd explicit acceptance criteria for prescription error handling.\nSpecify validation rules for dosage and duplicate drugs.\nInclude system actor details for approval workflow.\n\nPersona\n\nYou are acting as a senior business analyst with 10+ years of experience in healthcare IT systems, specializing in EHR (Electronic Health Records), clinical workflow automation, and regulatory compliance (HIPAA, HL7, PoPIA).\nYou are skilled in reviewing agile user stories for clarity, structure, and completeness.\n\n\nT – Tone\n\nProfessional, analytical, and constructive — similar to a BA review summary for a healthcare project stakeholder meeting.\nAvoid generic feedback; emphasize actionable, healthcare-specific improvements. \n\n\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "userStory": {
                "advanced": false,
                "display_name": "userStory",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "userStory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-oCl1e",
        "measured": {
          "height": 365,
          "width": 320
        },
        "position": {
          "x": 1256.7999999999997,
          "y": 150.76
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GroqModel-rxKTk",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Groq.",
            "display_name": "Groq",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "api_key",
              "base_url",
              "max_tokens",
              "temperature",
              "n",
              "model_name",
              "tool_model_enabled"
            ],
            "frozen": false,
            "icon": "Groq",
            "last_updated": "2026-01-31T12:59:18.365Z",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "2aee7de6ee88",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  },
                  {
                    "name": "langchain_groq",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 3
              },
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ],
              "module": "lfx.components.groq.groq.GroqModel"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "loop_types": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "d1b9d198-5844-45be-86b3-50756d36bee5"
              },
              "_frontend_node_folder_id": {
                "value": "00963bd6-b531-4d5e-bcbf-de1112750e10"
              },
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Groq API Key",
                "dynamic": false,
                "info": "API key for the Groq API.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "base_url": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Groq API Base",
                "dynamic": false,
                "info": "Base URL path for API requests, leave blank if not using a proxy or service emulator.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "base_url",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "https://api.groq.com"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pydantic.v1 import SecretStr\n\nfrom lfx.base.models.groq_constants import GROQ_MODELS\nfrom lfx.base.models.groq_model_discovery import get_groq_models\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput, SliderInput\nfrom lfx.log.logger import logger\n\n\nclass GroqModel(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n    name = \"GroqModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        SecretStrInput(\n            name=\"api_key\", display_name=\"Groq API Key\", info=\"API key for the Groq API.\", real_time_refresh=True\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Groq API Base\",\n            info=\"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n            advanced=True,\n            value=\"https://api.groq.com\",\n            real_time_refresh=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use. Add your Groq API key to access additional available models.\",\n            options=GROQ_MODELS,\n            value=GROQ_MODELS[0],\n            refresh_button=True,\n            combobox=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Enable Tool Models\",\n            info=(\n                \"Select if you want to use models that can work with tools. If yes, only those models will be shown.\"\n            ),\n            advanced=False,\n            value=False,\n            real_time_refresh=True,\n        ),\n    ]\n\n    def get_models(self, *, tool_model_enabled: bool | None = None) -> list[str]:\n        \"\"\"Get available Groq models using the dynamic discovery system.\n\n        This method uses the groq_model_discovery module which:\n        - Fetches models directly from Groq API\n        - Automatically tests tool calling support\n        - Caches results for 24 hours\n        - Falls back to hardcoded list if API fails\n\n        Args:\n            tool_model_enabled: If True, only return models that support tool calling\n\n        Returns:\n            List of available model IDs\n        \"\"\"\n        try:\n            # Get models with metadata from dynamic discovery system\n            api_key = self.api_key if hasattr(self, \"api_key\") and self.api_key else None\n            models_metadata = get_groq_models(api_key=api_key)\n\n            # Filter out non-LLM models (audio, TTS, guards)\n            model_ids = [\n                model_id for model_id, metadata in models_metadata.items() if not metadata.get(\"not_supported\", False)\n            ]\n\n            # Filter by tool calling support if requested\n            if tool_model_enabled:\n                model_ids = [model_id for model_id in model_ids if models_metadata[model_id].get(\"tool_calling\", False)]\n                logger.info(f\"Loaded {len(model_ids)} Groq models with tool calling support\")\n            else:\n                logger.info(f\"Loaded {len(model_ids)} Groq models\")\n        except (ValueError, KeyError, TypeError, ImportError) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            # Fallback to hardcoded list from groq_constants.py\n            return GROQ_MODELS\n        else:\n            return model_ids\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) != 0:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ValueError, KeyError, TypeError, ImportError) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GROQ_MODELS\n                    build_config.setdefault(\"model_name\", {})\n                    build_config[\"model_name\"][\"options\"] = ids\n                    build_config[\"model_name\"].setdefault(\"value\", ids[0])\n            except (ValueError, KeyError, TypeError, AttributeError) as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_groq import ChatGroq\n        except ImportError as e:\n            msg = \"langchain-groq is not installed. Please install it with `pip install langchain-groq`.\"\n            raise ImportError(msg) from e\n\n        return ChatGroq(\n            model=self.model_name,\n            max_tokens=self.max_tokens or None,\n            temperature=self.temperature,\n            base_url=self.base_url,\n            n=self.n or 1,\n            api_key=SecretStr(self.api_key).get_secret_value(),\n            streaming=self.stream,\n        )\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Output Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "external_options": {},
                "info": "The name of the model to use. Add your Groq API key to access additional available models.",
                "name": "model_name",
                "options": [
                  "llama-3.1-8b-instant",
                  "llama-3.3-70b-versatile"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "llama-3.3-70b-versatile"
              },
              "n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "N",
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Run inference with this temperature. Must by in the closed interval [0.0, 1.0].",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "override_skip": false,
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "track_in_telemetry": false,
                "type": "slider",
                "value": 0.1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Enable Tool Models",
                "dynamic": false,
                "info": "Select if you want to use models that can work with tools. If yes, only those models will be shown.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "GroqModel"
        },
        "dragging": false,
        "id": "GroqModel-rxKTk",
        "measured": {
          "height": 492,
          "width": 320
        },
        "position": {
          "x": 1715.1999999999998,
          "y": 138.28000000000014
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SaveToFile-YfDpR",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Save data to local file, AWS S3, or Google Drive in the selected format.",
            "display_name": "Write File",
            "documentation": "https://docs.langflow.org/write-file",
            "edited": false,
            "field_order": [
              "storage_location",
              "input",
              "file_name",
              "append_mode",
              "local_format",
              "aws_format",
              "gdrive_format",
              "aws_access_key_id",
              "aws_secret_access_key",
              "bucket_name",
              "aws_region",
              "s3_prefix",
              "service_account_key",
              "folder_id"
            ],
            "frozen": false,
            "icon": "file-text",
            "last_updated": "2026-01-31T12:59:17.430Z",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "9fb8e92f7b34",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "pandas",
                    "version": "2.2.3"
                  },
                  {
                    "name": "fastapi",
                    "version": "1.4.1"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  },
                  {
                    "name": "langflow",
                    "version": "1.7.2"
                  },
                  {
                    "name": "boto3",
                    "version": "1.40.61"
                  },
                  {
                    "name": "google",
                    "version": "1.72.0"
                  },
                  {
                    "name": "googleapiclient",
                    "version": "2.154.0"
                  }
                ],
                "total_dependencies": 8
              },
              "module": "lfx.components.files_and_knowledge.save_file.SaveToFileComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "File Path",
                "group_outputs": false,
                "loop_types": null,
                "method": "save_to_file",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "d1b9d198-5844-45be-86b3-50756d36bee5"
              },
              "_frontend_node_folder_id": {
                "value": "00963bd6-b531-4d5e-bcbf-de1112750e10"
              },
              "_type": "Component",
              "append_mode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Append",
                "dynamic": false,
                "info": "Append to file if it exists (only for Local storage with plain text formats). Not supported for cloud storage (AWS/Google Drive).",
                "list": false,
                "list_add_label": "Add More",
                "name": "append_mode",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "aws_access_key_id": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "AWS Access Key ID",
                "dynamic": false,
                "info": "AWS Access key ID.",
                "input_types": [],
                "load_from_db": false,
                "name": "aws_access_key_id",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "aws_format": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "File Format",
                "dynamic": false,
                "external_options": {},
                "info": "Select the file format for AWS S3 storage.",
                "name": "aws_format",
                "options": [
                  "txt",
                  "json",
                  "csv",
                  "xml",
                  "html",
                  "md",
                  "yaml",
                  "log",
                  "tsv",
                  "jsonl",
                  "parquet",
                  "xlsx",
                  "zip"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "txt"
              },
              "aws_region": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "AWS Region",
                "dynamic": false,
                "info": "AWS region (e.g., us-east-1, eu-west-1).",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "aws_region",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "aws_secret_access_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "AWS Secret Key",
                "dynamic": false,
                "info": "AWS Secret Key.",
                "input_types": [],
                "load_from_db": false,
                "name": "aws_secret_access_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "bucket_name": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "S3 Bucket Name",
                "dynamic": false,
                "info": "Enter the name of the S3 bucket.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "bucket_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom collections.abc import AsyncIterator, Iterator\nfrom pathlib import Path\n\nimport orjson\nimport pandas as pd\nfrom fastapi import UploadFile\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.custom import Component\nfrom lfx.inputs import SortableListInput\nfrom lfx.io import BoolInput, DropdownInput, HandleInput, SecretStrInput, StrInput\nfrom lfx.schema import Data, DataFrame, Message\nfrom lfx.services.deps import get_settings_service, get_storage_service, session_scope\nfrom lfx.template.field.base import Output\nfrom lfx.utils.validate_cloud import is_astra_cloud_environment\n\n\ndef _get_storage_location_options():\n    \"\"\"Get storage location options, filtering out Local if in Astra cloud environment.\"\"\"\n    all_options = [{\"name\": \"AWS\", \"icon\": \"Amazon\"}, {\"name\": \"Google Drive\", \"icon\": \"google\"}]\n    if is_astra_cloud_environment():\n        return all_options\n    return [{\"name\": \"Local\", \"icon\": \"hard-drive\"}, *all_options]\n\n\nclass SaveToFileComponent(Component):\n    display_name = \"Write File\"\n    description = \"Save data to local file, AWS S3, or Google Drive in the selected format.\"\n    documentation: str = \"https://docs.langflow.org/write-file\"\n    icon = \"file-text\"\n    name = \"SaveToFile\"\n\n    # File format options for different storage types\n    LOCAL_DATA_FORMAT_CHOICES = [\"csv\", \"excel\", \"json\", \"markdown\"]\n    LOCAL_MESSAGE_FORMAT_CHOICES = [\"txt\", \"json\", \"markdown\"]\n    AWS_FORMAT_CHOICES = [\n        \"txt\",\n        \"json\",\n        \"csv\",\n        \"xml\",\n        \"html\",\n        \"md\",\n        \"yaml\",\n        \"log\",\n        \"tsv\",\n        \"jsonl\",\n        \"parquet\",\n        \"xlsx\",\n        \"zip\",\n    ]\n    GDRIVE_FORMAT_CHOICES = [\"txt\", \"json\", \"csv\", \"xlsx\", \"slides\", \"docs\", \"jpg\", \"mp3\"]\n\n    inputs = [\n        # Storage location selection\n        SortableListInput(\n            name=\"storage_location\",\n            display_name=\"Storage Location\",\n            placeholder=\"Select Location\",\n            info=\"Choose where to save the file.\",\n            options=_get_storage_location_options(),\n            real_time_refresh=True,\n            limit=1,\n        ),\n        # Common inputs\n        HandleInput(\n            name=\"input\",\n            display_name=\"File Content\",\n            info=\"The input to save.\",\n            dynamic=True,\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        StrInput(\n            name=\"file_name\",\n            display_name=\"File Name\",\n            info=\"Name file will be saved as (without extension).\",\n            required=True,\n            show=False,\n            tool_mode=True,\n        ),\n        BoolInput(\n            name=\"append_mode\",\n            display_name=\"Append\",\n            info=(\n                \"Append to file if it exists (only for Local storage with plain text formats). \"\n                \"Not supported for cloud storage (AWS/Google Drive).\"\n            ),\n            value=False,\n            show=False,\n        ),\n        # Format inputs (dynamic based on storage location)\n        DropdownInput(\n            name=\"local_format\",\n            display_name=\"File Format\",\n            options=list(dict.fromkeys(LOCAL_DATA_FORMAT_CHOICES + LOCAL_MESSAGE_FORMAT_CHOICES)),\n            info=\"Select the file format for local storage.\",\n            value=\"json\",\n            show=False,\n        ),\n        DropdownInput(\n            name=\"aws_format\",\n            display_name=\"File Format\",\n            options=AWS_FORMAT_CHOICES,\n            info=\"Select the file format for AWS S3 storage.\",\n            value=\"txt\",\n            show=False,\n        ),\n        DropdownInput(\n            name=\"gdrive_format\",\n            display_name=\"File Format\",\n            options=GDRIVE_FORMAT_CHOICES,\n            info=\"Select the file format for Google Drive storage.\",\n            value=\"txt\",\n            show=False,\n        ),\n        # AWS S3 specific inputs\n        SecretStrInput(\n            name=\"aws_access_key_id\",\n            display_name=\"AWS Access Key ID\",\n            info=\"AWS Access key ID.\",\n            show=False,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"aws_secret_access_key\",\n            display_name=\"AWS Secret Key\",\n            info=\"AWS Secret Key.\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"bucket_name\",\n            display_name=\"S3 Bucket Name\",\n            info=\"Enter the name of the S3 bucket.\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"aws_region\",\n            display_name=\"AWS Region\",\n            info=\"AWS region (e.g., us-east-1, eu-west-1).\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"s3_prefix\",\n            display_name=\"S3 Prefix\",\n            info=\"Prefix for all files in S3.\",\n            show=False,\n            advanced=True,\n        ),\n        # Google Drive specific inputs\n        SecretStrInput(\n            name=\"service_account_key\",\n            display_name=\"GCP Credentials Secret Key\",\n            info=\"Your Google Cloud Platform service account JSON key as a secret string (complete JSON content).\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"folder_id\",\n            display_name=\"Google Drive Folder ID\",\n            info=(\n                \"The Google Drive folder ID where the file will be uploaded. \"\n                \"The folder must be shared with the service account email.\"\n            ),\n            required=True,\n            show=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(display_name=\"File Path\", name=\"message\", method=\"save_to_file\")]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Update build configuration to show/hide fields based on storage location selection.\"\"\"\n        # Update options dynamically based on cloud environment\n        # This ensures options are refreshed when build_config is updated\n        if \"storage_location\" in build_config:\n            updated_options = _get_storage_location_options()\n            build_config[\"storage_location\"][\"options\"] = updated_options\n\n        if field_name != \"storage_location\":\n            return build_config\n\n        # Extract selected storage location\n        selected = [location[\"name\"] for location in field_value] if isinstance(field_value, list) else []\n\n        # Hide all dynamic fields first\n        dynamic_fields = [\n            \"file_name\",  # Common fields (input is always visible)\n            \"append_mode\",\n            \"local_format\",\n            \"aws_format\",\n            \"gdrive_format\",\n            \"aws_access_key_id\",\n            \"aws_secret_access_key\",\n            \"bucket_name\",\n            \"aws_region\",\n            \"s3_prefix\",\n            \"service_account_key\",\n            \"folder_id\",\n        ]\n\n        for f_name in dynamic_fields:\n            if f_name in build_config:\n                build_config[f_name][\"show\"] = False\n\n        # Show fields based on selected storage location\n        if len(selected) == 1:\n            location = selected[0]\n\n            # Show file_name when any storage location is selected\n            if \"file_name\" in build_config:\n                build_config[\"file_name\"][\"show\"] = True\n\n            # Show append_mode only for Local storage (not supported for cloud storage)\n            if \"append_mode\" in build_config:\n                build_config[\"append_mode\"][\"show\"] = location == \"Local\"\n\n            if location == \"Local\":\n                if \"local_format\" in build_config:\n                    build_config[\"local_format\"][\"show\"] = True\n\n            elif location == \"AWS\":\n                aws_fields = [\n                    \"aws_format\",\n                    \"aws_access_key_id\",\n                    \"aws_secret_access_key\",\n                    \"bucket_name\",\n                    \"aws_region\",\n                    \"s3_prefix\",\n                ]\n                for f_name in aws_fields:\n                    if f_name in build_config:\n                        build_config[f_name][\"show\"] = True\n\n            elif location == \"Google Drive\":\n                gdrive_fields = [\"gdrive_format\", \"service_account_key\", \"folder_id\"]\n                for f_name in gdrive_fields:\n                    if f_name in build_config:\n                        build_config[f_name][\"show\"] = True\n\n        return build_config\n\n    async def save_to_file(self) -> Message:\n        \"\"\"Save the input to a file and upload it, returning a confirmation message.\"\"\"\n        # Validate inputs\n        if not self.file_name:\n            msg = \"File name must be provided.\"\n            raise ValueError(msg)\n        if not self._get_input_type():\n            msg = \"Input type is not set.\"\n            raise ValueError(msg)\n\n        # Get selected storage location\n        storage_location = self._get_selected_storage_location()\n        if not storage_location:\n            msg = \"Storage location must be selected.\"\n            raise ValueError(msg)\n\n        # Check if Local storage is disabled in cloud environment\n        if storage_location == \"Local\" and is_astra_cloud_environment():\n            msg = \"Local storage is not available in cloud environment. Please use AWS or Google Drive.\"\n            raise ValueError(msg)\n\n        # Route to appropriate save method based on storage location\n        if storage_location == \"Local\":\n            return await self._save_to_local()\n        if storage_location == \"AWS\":\n            return await self._save_to_aws()\n        if storage_location == \"Google Drive\":\n            return await self._save_to_google_drive()\n        msg = f\"Unsupported storage location: {storage_location}\"\n        raise ValueError(msg)\n\n    def _get_input_type(self) -> str:\n        \"\"\"Determine the input type based on the provided input.\"\"\"\n        # Use exact type checking (type() is) instead of isinstance() to avoid inheritance issues.\n        # Since Message inherits from Data, isinstance(message, Data) would return True for Message objects,\n        # causing Message inputs to be incorrectly identified as Data type.\n        if type(self.input) is DataFrame:\n            return \"DataFrame\"\n        if type(self.input) is Message:\n            return \"Message\"\n        if type(self.input) is Data:\n            return \"Data\"\n        msg = f\"Unsupported input type: {type(self.input)}\"\n        raise ValueError(msg)\n\n    def _get_default_format(self) -> str:\n        \"\"\"Return the default file format based on input type.\"\"\"\n        if self._get_input_type() == \"DataFrame\":\n            return \"csv\"\n        if self._get_input_type() == \"Data\":\n            return \"json\"\n        if self._get_input_type() == \"Message\":\n            return \"json\"\n        return \"json\"  # Fallback\n\n    def _adjust_file_path_with_format(self, path: Path, fmt: str) -> Path:\n        \"\"\"Adjust the file path to include the correct extension.\"\"\"\n        file_extension = path.suffix.lower().lstrip(\".\")\n        if fmt == \"excel\":\n            return Path(f\"{path}.xlsx\").expanduser() if file_extension not in [\"xlsx\", \"xls\"] else path\n        return Path(f\"{path}.{fmt}\").expanduser() if file_extension != fmt else path\n\n    def _is_plain_text_format(self, fmt: str) -> bool:\n        \"\"\"Check if a file format is plain text (supports appending).\"\"\"\n        plain_text_formats = [\"txt\", \"json\", \"markdown\", \"md\", \"csv\", \"xml\", \"html\", \"yaml\", \"log\", \"tsv\", \"jsonl\"]\n        return fmt.lower() in plain_text_formats\n\n    async def _upload_file(self, file_path: Path) -> None:\n        \"\"\"Upload the saved file using the upload_user_file service.\"\"\"\n        from langflow.api.v2.files import upload_user_file\n        from langflow.services.database.models.user.crud import get_user_by_id\n\n        # Ensure the file exists\n        if not file_path.exists():\n            msg = f\"File not found: {file_path}\"\n            raise FileNotFoundError(msg)\n\n        # Upload the file - always use append=False because the local file already contains\n        # the correct content (either new or appended locally)\n        with file_path.open(\"rb\") as f:\n            async with session_scope() as db:\n                if not self.user_id:\n                    msg = \"User ID is required for file saving.\"\n                    raise ValueError(msg)\n                current_user = await get_user_by_id(db, self.user_id)\n\n                await upload_user_file(\n                    file=UploadFile(filename=file_path.name, file=f, size=file_path.stat().st_size),\n                    session=db,\n                    current_user=current_user,\n                    storage_service=get_storage_service(),\n                    settings_service=get_settings_service(),\n                    append=False,\n                )\n\n    def _save_dataframe(self, dataframe: DataFrame, path: Path, fmt: str) -> str:\n        \"\"\"Save a DataFrame to the specified file format.\"\"\"\n        append_mode = getattr(self, \"append_mode\", False)\n        should_append = append_mode and path.exists() and self._is_plain_text_format(fmt)\n\n        if fmt == \"csv\":\n            dataframe.to_csv(path, index=False, mode=\"a\" if should_append else \"w\", header=not should_append)\n        elif fmt == \"excel\":\n            dataframe.to_excel(path, index=False, engine=\"openpyxl\")\n        elif fmt == \"json\":\n            if should_append:\n                # Read and parse existing JSON\n                existing_data = []\n                try:\n                    existing_content = path.read_text(encoding=\"utf-8\").strip()\n                    if existing_content:\n                        parsed = json.loads(existing_content)\n                        # Handle case where existing content is a single object\n                        if isinstance(parsed, dict):\n                            existing_data = [parsed]\n                        elif isinstance(parsed, list):\n                            existing_data = parsed\n                except (json.JSONDecodeError, FileNotFoundError):\n                    # Treat parse errors or missing file as empty array\n                    existing_data = []\n\n                # Append new data\n                new_records = json.loads(dataframe.to_json(orient=\"records\"))\n                existing_data.extend(new_records)\n\n                # Write back as a single JSON array\n                path.write_text(json.dumps(existing_data, indent=2), encoding=\"utf-8\")\n            else:\n                dataframe.to_json(path, orient=\"records\", indent=2)\n        elif fmt == \"markdown\":\n            content = dataframe.to_markdown(index=False)\n            if should_append:\n                path.write_text(path.read_text(encoding=\"utf-8\") + \"\\n\\n\" + content, encoding=\"utf-8\")\n            else:\n                path.write_text(content, encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported DataFrame format: {fmt}\"\n            raise ValueError(msg)\n        action = \"appended to\" if should_append else \"saved successfully as\"\n        return f\"DataFrame {action} '{path}'\"\n\n    def _save_data(self, data: Data, path: Path, fmt: str) -> str:\n        \"\"\"Save a Data object to the specified file format.\"\"\"\n        append_mode = getattr(self, \"append_mode\", False)\n        should_append = append_mode and path.exists() and self._is_plain_text_format(fmt)\n\n        if fmt == \"csv\":\n            pd.DataFrame(data.data).to_csv(\n                path,\n                index=False,\n                mode=\"a\" if should_append else \"w\",\n                header=not should_append,\n            )\n        elif fmt == \"excel\":\n            pd.DataFrame(data.data).to_excel(path, index=False, engine=\"openpyxl\")\n        elif fmt == \"json\":\n            new_data = jsonable_encoder(data.data)\n            if should_append:\n                # Read and parse existing JSON\n                existing_data = []\n                try:\n                    existing_content = path.read_text(encoding=\"utf-8\").strip()\n                    if existing_content:\n                        parsed = json.loads(existing_content)\n                        # Handle case where existing content is a single object\n                        if isinstance(parsed, dict):\n                            existing_data = [parsed]\n                        elif isinstance(parsed, list):\n                            existing_data = parsed\n                except (json.JSONDecodeError, FileNotFoundError):\n                    # Treat parse errors or missing file as empty array\n                    existing_data = []\n\n                # Append new data\n                if isinstance(new_data, list):\n                    existing_data.extend(new_data)\n                else:\n                    existing_data.append(new_data)\n\n                # Write back as a single JSON array\n                path.write_text(json.dumps(existing_data, indent=2), encoding=\"utf-8\")\n            else:\n                content = orjson.dumps(new_data, option=orjson.OPT_INDENT_2).decode(\"utf-8\")\n                path.write_text(content, encoding=\"utf-8\")\n        elif fmt == \"markdown\":\n            content = pd.DataFrame(data.data).to_markdown(index=False)\n            if should_append:\n                path.write_text(path.read_text(encoding=\"utf-8\") + \"\\n\\n\" + content, encoding=\"utf-8\")\n            else:\n                path.write_text(content, encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported Data format: {fmt}\"\n            raise ValueError(msg)\n        action = \"appended to\" if should_append else \"saved successfully as\"\n        return f\"Data {action} '{path}'\"\n\n    async def _save_message(self, message: Message, path: Path, fmt: str) -> str:\n        \"\"\"Save a Message to the specified file format, handling async iterators.\"\"\"\n        content = \"\"\n        if message.text is None:\n            content = \"\"\n        elif isinstance(message.text, AsyncIterator):\n            async for item in message.text:\n                content += str(item) + \" \"\n            content = content.strip()\n        elif isinstance(message.text, Iterator):\n            content = \" \".join(str(item) for item in message.text)\n        else:\n            content = str(message.text)\n\n        append_mode = getattr(self, \"append_mode\", False)\n        should_append = append_mode and path.exists() and self._is_plain_text_format(fmt)\n\n        if fmt == \"txt\":\n            if should_append:\n                path.write_text(path.read_text(encoding=\"utf-8\") + \"\\n\" + content, encoding=\"utf-8\")\n            else:\n                path.write_text(content, encoding=\"utf-8\")\n        elif fmt == \"json\":\n            new_message = {\"message\": content}\n            if should_append:\n                # Read and parse existing JSON\n                existing_data = []\n                try:\n                    existing_content = path.read_text(encoding=\"utf-8\").strip()\n                    if existing_content:\n                        parsed = json.loads(existing_content)\n                        # Handle case where existing content is a single object\n                        if isinstance(parsed, dict):\n                            existing_data = [parsed]\n                        elif isinstance(parsed, list):\n                            existing_data = parsed\n                except (json.JSONDecodeError, FileNotFoundError):\n                    # Treat parse errors or missing file as empty array\n                    existing_data = []\n\n                # Append new message\n                existing_data.append(new_message)\n\n                # Write back as a single JSON array\n                path.write_text(json.dumps(existing_data, indent=2), encoding=\"utf-8\")\n            else:\n                path.write_text(json.dumps(new_message, indent=2), encoding=\"utf-8\")\n        elif fmt == \"markdown\":\n            md_content = f\"**Message:**\\n\\n{content}\"\n            if should_append:\n                path.write_text(path.read_text(encoding=\"utf-8\") + \"\\n\\n\" + md_content, encoding=\"utf-8\")\n            else:\n                path.write_text(md_content, encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported Message format: {fmt}\"\n            raise ValueError(msg)\n        action = \"appended to\" if should_append else \"saved successfully as\"\n        return f\"Message {action} '{path}'\"\n\n    def _get_selected_storage_location(self) -> str:\n        \"\"\"Get the selected storage location from the SortableListInput.\"\"\"\n        if hasattr(self, \"storage_location\") and self.storage_location:\n            if isinstance(self.storage_location, list) and len(self.storage_location) > 0:\n                return self.storage_location[0].get(\"name\", \"\")\n            if isinstance(self.storage_location, dict):\n                return self.storage_location.get(\"name\", \"\")\n        return \"\"\n\n    def _get_file_format_for_location(self, location: str) -> str:\n        \"\"\"Get the appropriate file format based on storage location.\"\"\"\n        if location == \"Local\":\n            return getattr(self, \"local_format\", None) or self._get_default_format()\n        if location == \"AWS\":\n            return getattr(self, \"aws_format\", \"txt\")\n        if location == \"Google Drive\":\n            return getattr(self, \"gdrive_format\", \"txt\")\n        return self._get_default_format()\n\n    async def _save_to_local(self) -> Message:\n        \"\"\"Save file to local storage (original functionality).\"\"\"\n        file_format = self._get_file_format_for_location(\"Local\")\n\n        # Validate file format based on input type\n        allowed_formats = (\n            self.LOCAL_MESSAGE_FORMAT_CHOICES if self._get_input_type() == \"Message\" else self.LOCAL_DATA_FORMAT_CHOICES\n        )\n        if file_format not in allowed_formats:\n            msg = f\"Invalid file format '{file_format}' for {self._get_input_type()}. Allowed: {allowed_formats}\"\n            raise ValueError(msg)\n\n        # Prepare file path\n        file_path = Path(self.file_name).expanduser()\n        if not file_path.parent.exists():\n            file_path.parent.mkdir(parents=True, exist_ok=True)\n        file_path = self._adjust_file_path_with_format(file_path, file_format)\n\n        # Save the input to file based on type\n        if self._get_input_type() == \"DataFrame\":\n            confirmation = self._save_dataframe(self.input, file_path, file_format)\n        elif self._get_input_type() == \"Data\":\n            confirmation = self._save_data(self.input, file_path, file_format)\n        elif self._get_input_type() == \"Message\":\n            confirmation = await self._save_message(self.input, file_path, file_format)\n        else:\n            msg = f\"Unsupported input type: {self._get_input_type()}\"\n            raise ValueError(msg)\n\n        # Upload the saved file\n        await self._upload_file(file_path)\n\n        # Return the final file path and confirmation message\n        final_path = Path.cwd() / file_path if not file_path.is_absolute() else file_path\n        return Message(text=f\"{confirmation} at {final_path}\")\n\n    async def _save_to_aws(self) -> Message:\n        \"\"\"Save file to AWS S3 using S3 functionality.\"\"\"\n        # Validate AWS credentials\n        if not getattr(self, \"aws_access_key_id\", None):\n            msg = \"AWS Access Key ID is required for S3 storage\"\n            raise ValueError(msg)\n        if not getattr(self, \"aws_secret_access_key\", None):\n            msg = \"AWS Secret Key is required for S3 storage\"\n            raise ValueError(msg)\n        if not getattr(self, \"bucket_name\", None):\n            msg = \"S3 Bucket Name is required for S3 storage\"\n            raise ValueError(msg)\n\n        # Use S3 upload functionality\n        try:\n            import boto3\n        except ImportError as e:\n            msg = \"boto3 is not installed. Please install it using `uv pip install boto3`.\"\n            raise ImportError(msg) from e\n\n        # Create S3 client\n        client_config = {\n            \"aws_access_key_id\": self.aws_access_key_id,\n            \"aws_secret_access_key\": self.aws_secret_access_key,\n        }\n\n        if hasattr(self, \"aws_region\") and self.aws_region:\n            client_config[\"region_name\"] = self.aws_region\n\n        s3_client = boto3.client(\"s3\", **client_config)\n\n        # Extract content\n        content = self._extract_content_for_upload()\n        file_format = self._get_file_format_for_location(\"AWS\")\n\n        # Generate file path\n        file_path = f\"{self.file_name}.{file_format}\"\n        if hasattr(self, \"s3_prefix\") and self.s3_prefix:\n            file_path = f\"{self.s3_prefix.rstrip('/')}/{file_path}\"\n\n        # Create temporary file\n        import tempfile\n\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", encoding=\"utf-8\", suffix=f\".{file_format}\", delete=False\n        ) as temp_file:\n            temp_file.write(content)\n            temp_file_path = temp_file.name\n\n        try:\n            # Upload to S3\n            s3_client.upload_file(temp_file_path, self.bucket_name, file_path)\n            s3_url = f\"s3://{self.bucket_name}/{file_path}\"\n            return Message(text=f\"File successfully uploaded to {s3_url}\")\n        finally:\n            # Clean up temp file\n            if Path(temp_file_path).exists():\n                Path(temp_file_path).unlink()\n\n    async def _save_to_google_drive(self) -> Message:\n        \"\"\"Save file to Google Drive using Google Drive functionality.\"\"\"\n        # Validate Google Drive credentials\n        if not getattr(self, \"service_account_key\", None):\n            msg = \"GCP Credentials Secret Key is required for Google Drive storage\"\n            raise ValueError(msg)\n        if not getattr(self, \"folder_id\", None):\n            msg = \"Google Drive Folder ID is required for Google Drive storage\"\n            raise ValueError(msg)\n\n        # Use Google Drive upload functionality\n        try:\n            import json\n            import tempfile\n\n            from google.oauth2 import service_account\n            from googleapiclient.discovery import build\n            from googleapiclient.http import MediaFileUpload\n        except ImportError as e:\n            msg = \"Google API client libraries are not installed. Please install them.\"\n            raise ImportError(msg) from e\n\n        # Parse credentials with multiple fallback strategies\n        credentials_dict = None\n        parse_errors = []\n\n        # Strategy 1: Parse as-is with strict=False to allow control characters\n        try:\n            credentials_dict = json.loads(self.service_account_key, strict=False)\n        except json.JSONDecodeError as e:\n            parse_errors.append(f\"Standard parse: {e!s}\")\n\n        # Strategy 2: Strip whitespace and try again\n        if credentials_dict is None:\n            try:\n                cleaned_key = self.service_account_key.strip()\n                credentials_dict = json.loads(cleaned_key, strict=False)\n            except json.JSONDecodeError as e:\n                parse_errors.append(f\"Stripped parse: {e!s}\")\n\n        # Strategy 3: Check if it's double-encoded (JSON string of a JSON string)\n        if credentials_dict is None:\n            try:\n                decoded_once = json.loads(self.service_account_key, strict=False)\n                if isinstance(decoded_once, str):\n                    credentials_dict = json.loads(decoded_once, strict=False)\n                else:\n                    credentials_dict = decoded_once\n            except json.JSONDecodeError as e:\n                parse_errors.append(f\"Double-encoded parse: {e!s}\")\n\n        # Strategy 4: Try to fix common issues with newlines in the private_key field\n        if credentials_dict is None:\n            try:\n                # Replace literal \\n with actual newlines which is common in pasted JSON\n                fixed_key = self.service_account_key.replace(\"\\\\n\", \"\\n\")\n                credentials_dict = json.loads(fixed_key, strict=False)\n            except json.JSONDecodeError as e:\n                parse_errors.append(f\"Newline-fixed parse: {e!s}\")\n\n        if credentials_dict is None:\n            error_details = \"; \".join(parse_errors)\n            msg = (\n                f\"Unable to parse service account key JSON. Tried multiple strategies: {error_details}. \"\n                \"Please ensure you've copied the entire JSON content from your service account key file. \"\n                \"The JSON should start with '{' and contain fields like 'type', 'project_id', 'private_key', etc.\"\n            )\n            raise ValueError(msg)\n\n        # Create Google Drive service with appropriate scopes\n        # Use drive scope for folder access, file scope is too restrictive for folder verification\n        credentials = service_account.Credentials.from_service_account_info(\n            credentials_dict, scopes=[\"https://www.googleapis.com/auth/drive\"]\n        )\n        drive_service = build(\"drive\", \"v3\", credentials=credentials)\n\n        # Extract content and format\n        content = self._extract_content_for_upload()\n        file_format = self._get_file_format_for_location(\"Google Drive\")\n\n        # Handle special Google Drive formats\n        if file_format in [\"slides\", \"docs\"]:\n            return await self._save_to_google_apps(drive_service, credentials, content, file_format)\n\n        # Create temporary file\n        file_path = f\"{self.file_name}.{file_format}\"\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\",\n            encoding=\"utf-8\",\n            suffix=f\".{file_format}\",\n            delete=False,\n        ) as temp_file:\n            temp_file.write(content)\n            temp_file_path = temp_file.name\n\n        try:\n            # Upload to Google Drive\n            # Note: We skip explicit folder verification since it requires broader permissions.\n            # If the folder doesn't exist or isn't accessible, the create() call will fail with a clear error.\n            file_metadata = {\"name\": file_path, \"parents\": [self.folder_id]}\n            media = MediaFileUpload(temp_file_path, resumable=True)\n\n            try:\n                uploaded_file = (\n                    drive_service.files().create(body=file_metadata, media_body=media, fields=\"id\").execute()\n                )\n            except Exception as e:\n                msg = (\n                    f\"Unable to upload file to Google Drive folder '{self.folder_id}'. \"\n                    f\"Error: {e!s}. \"\n                    \"Please ensure: 1) The folder ID is correct, 2) The folder exists, \"\n                    \"3) The service account has been granted access to this folder.\"\n                )\n                raise ValueError(msg) from e\n\n            file_id = uploaded_file.get(\"id\")\n            file_url = f\"https://drive.google.com/file/d/{file_id}/view\"\n            return Message(text=f\"File successfully uploaded to Google Drive: {file_url}\")\n        finally:\n            # Clean up temp file\n            if Path(temp_file_path).exists():\n                Path(temp_file_path).unlink()\n\n    async def _save_to_google_apps(self, drive_service, credentials, content: str, app_type: str) -> Message:\n        \"\"\"Save content to Google Apps (Slides or Docs).\"\"\"\n        import time\n\n        if app_type == \"slides\":\n            from googleapiclient.discovery import build\n\n            slides_service = build(\"slides\", \"v1\", credentials=credentials)\n\n            file_metadata = {\n                \"name\": self.file_name,\n                \"mimeType\": \"application/vnd.google-apps.presentation\",\n                \"parents\": [self.folder_id],\n            }\n\n            created_file = drive_service.files().create(body=file_metadata, fields=\"id\").execute()\n            presentation_id = created_file[\"id\"]\n\n            time.sleep(2)  # Wait for file to be available  # noqa: ASYNC251\n\n            presentation = slides_service.presentations().get(presentationId=presentation_id).execute()\n            slide_id = presentation[\"slides\"][0][\"objectId\"]\n\n            # Add content to slide\n            requests = [\n                {\n                    \"createShape\": {\n                        \"objectId\": \"TextBox_01\",\n                        \"shapeType\": \"TEXT_BOX\",\n                        \"elementProperties\": {\n                            \"pageObjectId\": slide_id,\n                            \"size\": {\n                                \"height\": {\"magnitude\": 3000000, \"unit\": \"EMU\"},\n                                \"width\": {\"magnitude\": 6000000, \"unit\": \"EMU\"},\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 1000000,\n                                \"translateY\": 1000000,\n                                \"unit\": \"EMU\",\n                            },\n                        },\n                    }\n                },\n                {\"insertText\": {\"objectId\": \"TextBox_01\", \"insertionIndex\": 0, \"text\": content}},\n            ]\n\n            slides_service.presentations().batchUpdate(\n                presentationId=presentation_id, body={\"requests\": requests}\n            ).execute()\n            file_url = f\"https://docs.google.com/presentation/d/{presentation_id}/edit\"\n\n        elif app_type == \"docs\":\n            from googleapiclient.discovery import build\n\n            docs_service = build(\"docs\", \"v1\", credentials=credentials)\n\n            file_metadata = {\n                \"name\": self.file_name,\n                \"mimeType\": \"application/vnd.google-apps.document\",\n                \"parents\": [self.folder_id],\n            }\n\n            created_file = drive_service.files().create(body=file_metadata, fields=\"id\").execute()\n            document_id = created_file[\"id\"]\n\n            time.sleep(2)  # Wait for file to be available  # noqa: ASYNC251\n\n            # Add content to document\n            requests = [{\"insertText\": {\"location\": {\"index\": 1}, \"text\": content}}]\n            docs_service.documents().batchUpdate(documentId=document_id, body={\"requests\": requests}).execute()\n            file_url = f\"https://docs.google.com/document/d/{document_id}/edit\"\n\n        return Message(text=f\"File successfully created in Google {app_type.title()}: {file_url}\")\n\n    def _extract_content_for_upload(self) -> str:\n        \"\"\"Extract content from input for upload to cloud services.\"\"\"\n        if self._get_input_type() == \"DataFrame\":\n            return self.input.to_csv(index=False)\n        if self._get_input_type() == \"Data\":\n            if hasattr(self.input, \"data\") and self.input.data:\n                if isinstance(self.input.data, dict):\n                    import json\n\n                    return json.dumps(self.input.data, indent=2, ensure_ascii=False)\n                return str(self.input.data)\n            return str(self.input)\n        if self._get_input_type() == \"Message\":\n            return str(self.input.text) if self.input.text else str(self.input)\n        return str(self.input)\n"
              },
              "file_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "File Name",
                "dynamic": false,
                "info": "Name file will be saved as (without extension).",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_name",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "C:\\Users\\vinot\\OneDrive\\Drive-Lenovo\\TestLeaf-GenAI-Intermediate\\Week1\\Assignment output\\UserStoryReviewScoreUserStoryReview"
              },
              "folder_id": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Google Drive Folder ID",
                "dynamic": false,
                "info": "The Google Drive folder ID where the file will be uploaded. The folder must be shared with the service account email.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "folder_id",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "gdrive_format": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "File Format",
                "dynamic": false,
                "external_options": {},
                "info": "Select the file format for Google Drive storage.",
                "name": "gdrive_format",
                "options": [
                  "txt",
                  "json",
                  "csv",
                  "xlsx",
                  "slides",
                  "docs",
                  "jpg",
                  "mp3"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "txt"
              },
              "input": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "File Content",
                "dynamic": true,
                "info": "The input to save.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "is_refresh": false,
              "local_format": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "File Format",
                "dynamic": false,
                "external_options": {},
                "info": "Select the file format for local storage.",
                "name": "local_format",
                "options": [
                  "csv",
                  "excel",
                  "json",
                  "markdown",
                  "txt"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "txt"
              },
              "s3_prefix": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "S3 Prefix",
                "dynamic": false,
                "info": "Prefix for all files in S3.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "s3_prefix",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "service_account_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "GCP Credentials Secret Key",
                "dynamic": false,
                "info": "Your Google Cloud Platform service account JSON key as a secret string (complete JSON content).",
                "input_types": [],
                "load_from_db": false,
                "name": "service_account_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "storage_location": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Storage Location",
                "dynamic": false,
                "info": "Choose where to save the file.",
                "limit": 1,
                "name": "storage_location",
                "options": [
                  {
                    "icon": "hard-drive",
                    "name": "Local"
                  },
                  {
                    "icon": "Amazon",
                    "name": "AWS"
                  },
                  {
                    "icon": "google",
                    "name": "Google Drive"
                  }
                ],
                "override_skip": false,
                "placeholder": "Select Location",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "icon": "hard-drive",
                    "name": "Local",
                    "selected": false
                  }
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SaveToFile"
        },
        "dragging": false,
        "id": "SaveToFile-YfDpR",
        "measured": {
          "height": 457,
          "width": 320
        },
        "position": {
          "x": 2191.3599999999997,
          "y": 166.6000000000001
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "APIRequest-WTvte",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Make HTTP requests using URL or cURL commands.",
            "display_name": "API Request",
            "documentation": "https://docs.langflow.org/api-request",
            "edited": false,
            "field_order": [
              "url_input",
              "curl_input",
              "method",
              "mode",
              "query_params",
              "body",
              "headers",
              "timeout",
              "follow_redirects",
              "save_to_file",
              "include_httpx_metadata"
            ],
            "frozen": false,
            "icon": "Globe",
            "last_updated": "2026-01-31T13:56:20.956Z",
            "legacy": false,
            "lf_version": "1.7.2",
            "metadata": {
              "code_hash": "04d62aab3a77",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "aiofiles",
                    "version": "24.1.0"
                  },
                  {
                    "name": "httpx",
                    "version": "0.28.1"
                  },
                  {
                    "name": "validators",
                    "version": "0.34.0"
                  },
                  {
                    "name": "lfx",
                    "version": "0.2.1"
                  }
                ],
                "total_dependencies": 4
              },
              "module": "lfx.components.data_source.api_request.APIRequestComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "API Response",
                "group_outputs": false,
                "loop_types": null,
                "method": "make_api_request",
                "name": "data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "d1b9d198-5844-45be-86b3-50756d36bee5"
              },
              "_frontend_node_folder_id": {
                "value": "00963bd6-b531-4d5e-bcbf-de1112750e10"
              },
              "_type": "Component",
              "body": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Body",
                "dynamic": false,
                "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT).",
                "input_types": [
                  "Data"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "body",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "description": "Parameter name",
                    "display_name": "Key",
                    "formatter": "text",
                    "name": "key",
                    "type": "str"
                  },
                  {
                    "description": "Parameter value",
                    "display_name": "Value",
                    "formatter": "text",
                    "name": "value"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "key": "jql",
                    "value": "key=SCRUM-15"
                  },
                  {
                    "key": "fields",
                    "value": "[\n        \"key\",\n        \"summary\",\n        \"description\",\n        \"status\",\n        \"reporter\"\n       \n    ]"
                  },
                  {
                    "key": "maxResults",
                    "value": "1"
                  }
                ]
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport re\nimport tempfile\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport aiofiles\nimport aiofiles.os as aiofiles_os\nimport httpx\nimport validators\n\nfrom lfx.base.curl.parse import parse_context\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import TabInput\nfrom lfx.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TableInput,\n)\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.utils.component_utils import set_current_fields, set_field_advanced, set_field_display\nfrom lfx.utils.ssrf_protection import SSRFProtectionError, validate_url_for_ssrf\n\n# Define fields for each mode\nMODE_FIELDS = {\n    \"URL\": [\n        \"url_input\",\n        \"method\",\n    ],\n    \"cURL\": [\"curl_input\"],\n}\n\n# Fields that should always be visible\nDEFAULT_FIELDS = [\"mode\"]\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = \"Make HTTP requests using URL or cURL commands.\"\n    documentation: str = \"https://docs.langflow.org/api-request\"\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"url_input\",\n            display_name=\"URL\",\n            info=\"Enter the URL for the request.\",\n            advanced=False,\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"curl_input\",\n            display_name=\"cURL\",\n            info=(\n                \"Paste a curl command to populate the fields. \"\n                \"This will fill in the dictionary fields for headers and body.\"\n            ),\n            real_time_refresh=True,\n            tool_mode=True,\n            advanced=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\n            value=\"GET\",\n            info=\"The HTTP method to use.\",\n            real_time_refresh=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"URL\", \"cURL\"],\n            value=\"URL\",\n            info=\"Enable cURL mode to populate fields from a cURL command.\",\n            real_time_refresh=True,\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT).\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Key\",\n                    \"type\": \"str\",\n                    \"description\": \"Parameter name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"description\": \"Parameter value\",\n                },\n            ],\n            value=[],\n            input_types=[\"Data\"],\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        TableInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Header\",\n                    \"type\": \"str\",\n                    \"description\": \"Header name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Header value\",\n                },\n            ],\n            value=[{\"key\": \"User-Agent\", \"value\": \"Langflow/1.0\"}],\n            advanced=True,\n            input_types=[\"Data\"],\n            real_time_refresh=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=30,\n            info=\"The timeout to use for the request.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"follow_redirects\",\n            display_name=\"Follow Redirects\",\n            value=False,\n            info=(\n                \"Whether to follow HTTP redirects. \"\n                \"WARNING: Enabling redirects may allow SSRF bypass attacks where a public URL \"\n                \"redirects to internal resources. Only enable if you trust the target server. \"\n                \"See OWASP SSRF Prevention Cheat Sheet for details.\"\n            ),\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"save_to_file\",\n            display_name=\"Save to File\",\n            value=False,\n            info=\"Save the API response to a temporary file\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_httpx_metadata\",\n            display_name=\"Include HTTPx Metadata\",\n            value=False,\n            info=(\n                \"Include properties such as headers, status_code, response_headers, \"\n                \"and redirection_history in the output.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"API Response\", name=\"data\", method=\"make_api_request\"),\n    ]\n\n    def _parse_json_value(self, value: Any) -> Any:\n        \"\"\"Parse a value that might be a JSON string.\"\"\"\n        if not isinstance(value, str):\n            return value\n\n        try:\n            parsed = json.loads(value)\n        except json.JSONDecodeError:\n            return value\n        else:\n            return parsed\n\n    def _process_body(self, body: Any) -> dict:\n        \"\"\"Process the body input into a valid dictionary.\"\"\"\n        if body is None:\n            return {}\n        if hasattr(body, \"data\"):\n            body = body.data\n        if isinstance(body, dict):\n            return self._process_dict_body(body)\n        if isinstance(body, str):\n            return self._process_string_body(body)\n        if isinstance(body, list):\n            return self._process_list_body(body)\n        return {}\n\n    def _process_dict_body(self, body: dict) -> dict:\n        \"\"\"Process dictionary body by parsing JSON values.\"\"\"\n        return {k: self._parse_json_value(v) for k, v in body.items()}\n\n    def _process_string_body(self, body: str) -> dict:\n        \"\"\"Process string body by attempting JSON parse.\"\"\"\n        try:\n            return self._process_body(json.loads(body))\n        except json.JSONDecodeError:\n            return {\"data\": body}\n\n    def _process_list_body(self, body: list) -> dict:\n        \"\"\"Process list body by converting to key-value dictionary.\"\"\"\n        processed_dict = {}\n        try:\n            for item in body:\n                # Unwrap Data objects\n                current_item = item\n                if hasattr(item, \"data\"):\n                    unwrapped_data = item.data\n                    # If the unwrapped data is a dict but not key-value format, use it directly\n                    if isinstance(unwrapped_data, dict) and not self._is_valid_key_value_item(unwrapped_data):\n                        return unwrapped_data\n                    current_item = unwrapped_data\n                if not self._is_valid_key_value_item(current_item):\n                    continue\n                key = current_item[\"key\"]\n                value = self._parse_json_value(current_item[\"value\"])\n                processed_dict[key] = value\n        except (KeyError, TypeError, ValueError) as e:\n            self.log(f\"Failed to process body list: {e}\")\n            return {}\n        return processed_dict\n\n    def _is_valid_key_value_item(self, item: Any) -> bool:\n        \"\"\"Check if an item is a valid key-value dictionary.\"\"\"\n        return isinstance(item, dict) and \"key\" in item and \"value\" in item\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        \"\"\"Parse a cURL command and update build configuration.\"\"\"\n        try:\n            parsed = parse_context(curl)\n\n            # Update basic configuration\n            url = parsed.url\n            # Normalize URL before setting it\n            url = self._normalize_url(url)\n\n            build_config[\"url_input\"][\"value\"] = url\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n\n            # Process headers\n            headers_list = [{\"key\": k, \"value\": v} for k, v in parsed.headers.items()]\n            build_config[\"headers\"][\"value\"] = headers_list\n\n            # Process body data\n            if not parsed.data:\n                build_config[\"body\"][\"value\"] = []\n            elif parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    if isinstance(json_data, dict):\n                        body_list = [\n                            {\"key\": k, \"value\": json.dumps(v) if isinstance(v, dict | list) else str(v)}\n                            for k, v in json_data.items()\n                        ]\n                        build_config[\"body\"][\"value\"] = body_list\n                    else:\n                        build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": json.dumps(json_data)}]\n                except json.JSONDecodeError:\n                    build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": parsed.data}]\n\n        except Exception as exc:\n            msg = f\"Error parsing curl: {exc}\"\n            self.log(msg)\n            raise ValueError(msg) from exc\n\n        return build_config\n\n    def _normalize_url(self, url: str) -> str:\n        \"\"\"Normalize URL by adding https:// if no protocol is specified.\"\"\"\n        if not url or not isinstance(url, str):\n            msg = \"URL cannot be empty\"\n            raise ValueError(msg)\n\n        url = url.strip()\n        if url.startswith((\"http://\", \"https://\")):\n            return url\n        return f\"https://{url}\"\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: dict | None = None,\n        body: Any = None,\n        timeout: int = 5,\n        *,\n        follow_redirects: bool = True,\n        save_to_file: bool = False,\n        include_httpx_metadata: bool = False,\n    ) -> Data:\n        method = method.upper()\n        if method not in {\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"}:\n            msg = f\"Unsupported method: {method}\"\n            raise ValueError(msg)\n\n        processed_body = self._process_body(body)\n        redirection_history = []\n\n        try:\n            # Prepare request parameters\n            request_params = {\n                \"method\": method,\n                \"url\": url,\n                \"headers\": headers,\n                \"json\": processed_body,\n                \"timeout\": timeout,\n                \"follow_redirects\": follow_redirects,\n            }\n            response = await client.request(**request_params)\n\n            redirection_history = [\n                {\n                    \"url\": redirect.headers.get(\"Location\", str(redirect.url)),\n                    \"status_code\": redirect.status_code,\n                }\n                for redirect in response.history\n            ]\n\n            is_binary, file_path = await self._response_info(response, with_file_path=save_to_file)\n            response_headers = self._headers_to_dict(response.headers)\n\n            # Base metadata\n            metadata = {\n                \"source\": url,\n                \"status_code\": response.status_code,\n                \"response_headers\": response_headers,\n            }\n\n            if redirection_history:\n                metadata[\"redirection_history\"] = redirection_history\n\n            if save_to_file:\n                mode = \"wb\" if is_binary else \"w\"\n                encoding = response.encoding if mode == \"w\" else None\n                if file_path:\n                    await aiofiles_os.makedirs(file_path.parent, exist_ok=True)\n                    if is_binary:\n                        async with aiofiles.open(file_path, \"wb\") as f:\n                            await f.write(response.content)\n                            await f.flush()\n                    else:\n                        async with aiofiles.open(file_path, \"w\", encoding=encoding) as f:\n                            await f.write(response.text)\n                            await f.flush()\n                    metadata[\"file_path\"] = str(file_path)\n\n                if include_httpx_metadata:\n                    metadata.update({\"headers\": headers})\n                return Data(data=metadata)\n\n            # Handle response content\n            if is_binary:\n                result = response.content\n            else:\n                try:\n                    result = response.json()\n                except json.JSONDecodeError:\n                    self.log(\"Failed to decode JSON response\")\n                    result = response.text.encode(\"utf-8\")\n\n            metadata[\"result\"] = result\n\n            if include_httpx_metadata:\n                metadata.update({\"headers\": headers})\n\n            return Data(data=metadata)\n        except (httpx.HTTPError, httpx.RequestError, httpx.TimeoutException) as exc:\n            self.log(f\"Error making request to {url}\")\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                    **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        \"\"\"Add query parameters to URL efficiently.\"\"\"\n        if not params:\n            return url\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    def _headers_to_dict(self, headers: httpx.Headers) -> dict[str, str]:\n        \"\"\"Convert HTTP headers to a dictionary with lowercased keys.\"\"\"\n        return {k.lower(): v for k, v in headers.items()}\n\n    def _process_headers(self, headers: Any) -> dict:\n        \"\"\"Process the headers input into a valid dictionary.\"\"\"\n        if headers is None:\n            return {}\n        if isinstance(headers, dict):\n            return headers\n        if isinstance(headers, list):\n            return {item[\"key\"]: item[\"value\"] for item in headers if self._is_valid_key_value_item(item)}\n        return {}\n\n    async def make_api_request(self) -> Data:\n        \"\"\"Make HTTP request with optimized parameter handling.\"\"\"\n        method = self.method\n        url = self.url_input.strip() if isinstance(self.url_input, str) else \"\"\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        follow_redirects = self.follow_redirects\n        save_to_file = self.save_to_file\n        include_httpx_metadata = self.include_httpx_metadata\n\n        # Security warning when redirects are enabled\n        if follow_redirects:\n            self.log(\n                \"Security Warning: HTTP redirects are enabled. This may allow SSRF bypass attacks \"\n                \"where a public URL redirects to internal resources (e.g., cloud metadata endpoints). \"\n                \"Only enable this if you trust the target server.\"\n            )\n\n        # if self.mode == \"cURL\" and self.curl_input:\n        #     self._build_config = self.parse_curl(self.curl_input, dotdict())\n        #     # After parsing curl, get the normalized URL\n        #     url = self._build_config[\"url_input\"][\"value\"]\n\n        # Normalize URL before validation\n        url = self._normalize_url(url)\n\n        # Validate URL\n        if not validators.url(url):\n            msg = f\"Invalid URL provided: {url}\"\n            raise ValueError(msg)\n\n        # SSRF Protection: Validate URL to prevent access to internal resources\n        # TODO: In next major version (2.0), remove warn_only=True to enforce blocking\n        try:\n            validate_url_for_ssrf(url, warn_only=True)\n        except SSRFProtectionError as e:\n            # This will only raise if SSRF protection is enabled and warn_only=False\n            msg = f\"SSRF Protection: {e}\"\n            raise ValueError(msg) from e\n\n        # Process query parameters\n        if isinstance(self.query_params, str):\n            query_params = dict(parse_qsl(self.query_params))\n        else:\n            query_params = self.query_params.data if self.query_params else {}\n\n        # Process headers and body\n        headers = self._process_headers(headers)\n        body = self._process_body(body)\n        url = self.add_query_params(url, query_params)\n\n        async with httpx.AsyncClient() as client:\n            result = await self.make_request(\n                client,\n                method,\n                url,\n                headers,\n                body,\n                timeout,\n                follow_redirects=follow_redirects,\n                save_to_file=save_to_file,\n                include_httpx_metadata=include_httpx_metadata,\n            )\n        self.status = result\n        return result\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        \"\"\"Update the build config based on the selected mode.\"\"\"\n        if field_name != \"mode\":\n            if field_name == \"curl_input\" and self.mode == \"cURL\" and self.curl_input:\n                return self.parse_curl(self.curl_input, build_config)\n            return build_config\n\n        # print(f\"Current mode: {field_value}\")\n        if field_value == \"cURL\":\n            set_field_display(build_config, \"curl_input\", value=True)\n            if build_config[\"curl_input\"][\"value\"]:\n                build_config = self.parse_curl(build_config[\"curl_input\"][\"value\"], build_config)\n        else:\n            set_field_display(build_config, \"curl_input\", value=False)\n\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=MODE_FIELDS,\n            selected_action=field_value,\n            default_fields=DEFAULT_FIELDS,\n            func=set_field_advanced,\n            default_value=True,\n        )\n\n    async def _response_info(\n        self, response: httpx.Response, *, with_file_path: bool = False\n    ) -> tuple[bool, Path | None]:\n        \"\"\"Determine the file path and whether the response content is binary.\n\n        Args:\n            response (Response): The HTTP response object.\n            with_file_path (bool): Whether to save the response content to a file.\n\n        Returns:\n            Tuple[bool, Path | None]:\n                A tuple containing a boolean indicating if the content is binary and the full file path (if applicable).\n        \"\"\"\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        is_binary = \"application/octet-stream\" in content_type or \"application/binary\" in content_type\n\n        if not with_file_path:\n            return is_binary, None\n\n        component_temp_dir = Path(tempfile.gettempdir()) / self.__class__.__name__\n\n        # Create directory asynchronously\n        await aiofiles_os.makedirs(component_temp_dir, exist_ok=True)\n\n        filename = None\n        if \"Content-Disposition\" in response.headers:\n            content_disposition = response.headers[\"Content-Disposition\"]\n            filename_match = re.search(r'filename=\"(.+?)\"', content_disposition)\n            if filename_match:\n                extracted_filename = filename_match.group(1)\n                filename = extracted_filename\n\n        # Step 3: Infer file extension or use part of the request URL if no filename\n        if not filename:\n            # Extract the last segment of the URL path\n            url_path = urlparse(str(response.request.url) if response.request else \"\").path\n            base_name = Path(url_path).name  # Get the last segment of the path\n            if not base_name:  # If the path ends with a slash or is empty\n                base_name = \"response\"\n\n            # Infer file extension\n            content_type_to_extension = {\n                \"text/plain\": \".txt\",\n                \"application/json\": \".json\",\n                \"image/jpeg\": \".jpg\",\n                \"image/png\": \".png\",\n                \"application/octet-stream\": \".bin\",\n            }\n            extension = content_type_to_extension.get(content_type, \".bin\" if is_binary else \".txt\")\n            filename = f\"{base_name}{extension}\"\n\n        # Step 4: Define the full file path\n        file_path = component_temp_dir / filename\n\n        # Step 5: Check if file exists asynchronously and handle accordingly\n        try:\n            # Try to create the file exclusively (x mode) to check existence\n            async with aiofiles.open(file_path, \"x\") as _:\n                pass  # File created successfully, we can use this path\n        except FileExistsError:\n            # If file exists, append a timestamp to the filename\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d%H%M%S%f\")\n            file_path = component_temp_dir / f\"{timestamp}-{filename}\"\n\n        return is_binary, file_path\n"
              },
              "curl_input": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "cURL",
                "dynamic": false,
                "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "curl_input",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "follow_redirects": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Follow Redirects",
                "dynamic": false,
                "info": "Whether to follow HTTP redirects. WARNING: Enabling redirects may allow SSRF bypass attacks where a public URL redirects to internal resources. Only enable if you trust the target server. See OWASP SSRF Prevention Cheat Sheet for details.",
                "list": false,
                "list_add_label": "Add More",
                "name": "follow_redirects",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "headers": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Headers",
                "dynamic": false,
                "info": "The headers to send with the request",
                "input_types": [
                  "Data"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "headers",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "description": "Header name",
                    "display_name": "Header",
                    "formatter": "text",
                    "name": "key",
                    "type": "str"
                  },
                  {
                    "description": "Header value",
                    "display_name": "Value",
                    "formatter": "text",
                    "name": "value",
                    "type": "str"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "key": "User-Agent",
                    "value": "Langflow/1.0"
                  },
                  {
                    "key": "Authorization",
                    "value": "Basic c2hhbmVhZ2xlMjFhaTNAZ21haWwuY29tOkFUQVRUM3hGZkdGMHl5U1Zla21KajI0N2FkTlN3dzJwVDhwX0NpZHNsemxWYVpuZ05fQTBTcmxjMEpRMkZiTGNYa0hNVERtUVdhQklsVUZQLUp1R01VSGsyNDhjRWdjejZOa3lQQ1dfZUdvWkNDVUJnX0RtU3JwdllaQjVOSEdkZkJ1M0s2Z2ptTW00YjIzcmdhWW5vNFBoRHFIYzRVWkhiRVQ3NFUyd3l6QXhxUGo0TVRCU21aOD03RTMyNTM3RA=="
                  }
                ]
              },
              "include_httpx_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Include HTTPx Metadata",
                "dynamic": false,
                "info": "Include properties such as headers, status_code, response_headers, and redirection_history in the output.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_httpx_metadata",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "is_refresh": false,
              "method": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Method",
                "dynamic": false,
                "external_options": {},
                "info": "The HTTP method to use.",
                "name": "method",
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "POST"
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Enable cURL mode to populate fields from a cURL command.",
                "name": "mode",
                "options": [
                  "URL",
                  "cURL"
                ],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "tab",
                "value": "URL"
              },
              "query_params": {
                "_input_type": "DataInput",
                "advanced": true,
                "display_name": "Query Parameters",
                "dynamic": false,
                "info": "The query parameters to append to the URL.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "query_params",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "save_to_file": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Save to File",
                "dynamic": false,
                "info": "Save the API response to a temporary file",
                "list": false,
                "list_add_label": "Add More",
                "name": "save_to_file",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout to use for the request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 30
              },
              "url_input": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URL",
                "dynamic": false,
                "info": "Enter the URL for the request.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "url_input",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "https://shaneagle21ai3.atlassian.net/rest/api/3/search/jql"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "APIRequest"
        },
        "dragging": false,
        "id": "APIRequest-WTvte",
        "measured": {
          "height": 536,
          "width": 320
        },
        "position": {
          "x": 25.30359482038409,
          "y": 165.66372347535506
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -878.565370736651,
      "y": 4.119618765087807,
      "zoom": 0.6790746874602954
    }
  },
  "description": "Your Hub for Text Generation.",
  "endpoint_name": null,
  "id": "d1b9d198-5844-45be-86b3-50756d36bee5",
  "is_component": false,
  "last_tested_version": "1.7.2",
  "name": "Week1 Day1",
  "tags": []
}
